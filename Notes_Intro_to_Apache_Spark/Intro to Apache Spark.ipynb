{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://changhsinlee.com/install-pyspark-windows-jupyter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Set Up Locally\n",
    "* Get Spark 2.3.2 from : https://spark.apache.org/downloads.html\n",
    "    * Pre-Built for Hadoop 2.7 or later\n",
    "    * Extract to `C:\\Users\\Ryan.nsj\\Spark`\n",
    "    * Add environment variable `SPARK_HOME` as `C:\\Users\\Ryan.nsj\\Spark\\spark-2.3.2-bin-hadoop2.7\\`\n",
    "    \n",
    "    \n",
    "* Get Java JDK 8 from : https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n",
    "\n",
    "\n",
    "* Get pyspark with : `pip install pyspark`\n",
    "* Get findspark with : `pip install findspark`\n",
    "* If getting `InvalidInputError`, try using directory names with no spaces or special charaters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkContext\n",
    "* __SparkContext__ object manages the connection to the __clusters__, and coordinates the running of processes on those clusters\n",
    "* More specifically, it connects to the __cluster managers__.\n",
    "* The cluster managers control the __executors__ on different __Worker Nodes__ that run the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find path to PySpark.\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Import PySpark and initialize SparkContext object.\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Resilient Distributed Data (RDD)\n",
    "* Immutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR\\tGoogleKnowlege_Occupation\\tShow\\tGroup\\tRaw_Guest_List',\n",
       " '1999\\tactor\\t1/11/99\\tActing\\tMichael J. Fox',\n",
       " '1999\\tComedian\\t1/12/99\\tComedy\\tSandra Bernhard',\n",
       " '1999\\ttelevision actress\\t1/13/99\\tActing\\tTracey Ullman',\n",
       " '1999\\tfilm actress\\t1/14/99\\tActing\\tGillian Anderson']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = sc.textFile(\"daily_show.tsv\")\n",
    "raw_data.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lazy code evaluation means that the reading in of the testFile is not executed until it is needed in the second command.\n",
    "* Allows to build a task queue that can be optimized by Spark in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipelining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Every operation or calculation in Spark is a series of __methods__ that we can chain together and run in succession to form a pipeline.\n",
    "* Each step in the pipeline returns either a Python value (such as an integer), a Python data structure (such as a dictionary), or an RDD object.  \n",
    "\n",
    "\n",
    "* __2 Method Types:__\n",
    "    * __Transformations__ - `map()`, `reduceByKey()`, `flatMap()`\n",
    "    * __Actions__ - `take()`, `reduce()`, `saveTextFile()`, `collect()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "* Returns reference to an RDD\n",
    "* Lazy operations, only run when another __action__ requires the use of the transformation's output RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _map(f)_\n",
    "* map(f) applies function `f` to every element in the target RDD.\n",
    "* Returns a new RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['YEAR', 'GoogleKnowlege_Occupation', 'Show', 'Group', 'Raw_Guest_List'],\n",
       " ['1999', 'actor', '1/11/99', 'Acting', 'Michael J. Fox'],\n",
       " ['1999', 'Comedian', '1/12/99', 'Comedy', 'Sandra Bernhard'],\n",
       " ['1999', 'television actress', '1/13/99', 'Acting', 'Tracey Ullman'],\n",
       " ['1999', 'film actress', '1/14/99', 'Acting', 'Gillian Anderson']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_show = raw_data.map(lambda line: line.split('\\t'))\n",
    "daily_show.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _reduceByKey(f)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map()\n",
    "# ('YEAR', 1)\n",
    "# ('1991', 1)\n",
    "# ('1991', 1)\n",
    "# ('1991', 1)\n",
    "# ('1991', 1)\n",
    "# ...\n",
    "\n",
    "# reduceByKey()\n",
    "# ('YEAR', 1)\n",
    "# ('1991', 4)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('YEAR', 1), ('2012', 164), ('2013', 166), ('2004', 164), ('2011', 163)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tally = daily_show.map(lambda x: (x[0], 1)).reduceByKey(lambda x,y: x+y)\n",
    "tally.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "tally_count = tally.count()\n",
    "print(tally_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('YEAR', 1),\n",
       " ('2012', 164),\n",
       " ('2013', 166),\n",
       " ('2004', 164),\n",
       " ('2011', 163),\n",
       " ('2014', 163),\n",
       " ('2002', 159),\n",
       " ('2007', 141),\n",
       " ('2015', 100),\n",
       " ('2003', 166),\n",
       " ('2010', 165),\n",
       " ('2001', 157),\n",
       " ('2000', 169),\n",
       " ('2008', 164),\n",
       " ('2005', 162),\n",
       " ('2009', 163),\n",
       " ('1999', 166),\n",
       " ('2006', 161)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tally.take(tally.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter(f)\n",
    "* filter() returns rows in the input RDD where function `f(row) == True`, and filters out rows where `f(row) == False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_year(line):\n",
    "    if line[0] == 'YEAR':\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "filtered_daily_show = daily_show.filter(lambda line: filter_year(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1999', 'actor', '1/11/99', 'Acting', 'Michael J. Fox'],\n",
       " ['1999', 'Comedian', '1/12/99', 'Comedy', 'Sandra Bernhard'],\n",
       " ['1999', 'television actress', '1/13/99', 'Acting', 'Tracey Ullman'],\n",
       " ['1999', 'film actress', '1/14/99', 'Acting', 'Gillian Anderson'],\n",
       " ['1999', 'actor', '1/18/99', 'Acting', 'David Alan Grier']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_daily_show.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline of Methods and Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('radio personality', 3),\n",
       " ('former governor of new york', 1),\n",
       " ('illustrator', 1),\n",
       " ('presidnet', 3),\n",
       " ('former united states secretary of state', 6)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_daily_show.filter(lambda line: line[1] != '') \\        # Remove Guests with profession as blank\n",
    "                   .map(lambda line: (line[1].lower(), 1)) \\    # Convert all to (profession,1) key-value pairs in lowercase\n",
    "                   .reduceByKey(lambda x,y: x+y) \\              # Collapse and count unique professions by key\n",
    "                   .take(5)                                     # Return the first 5 (unsorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rank,Major_code,Major,Total,Men,Women,Major_category,ShareWomen,Sample_size,Employed,Full_time,Part_time,Full_time_year_round,Unemployed,Unemployment_rate,Median,P25th,P75th,College_jobs,Non_college_jobs,Low_wage_jobs'],\n",
       " ['1,2419,PETROLEUM ENGINEERING,2339,2057,282,Engineering,0.120564344,36,1976,1849,270,1207,37,0.018380527,110000,95000,125000,1534,364,193'],\n",
       " ['2,2416,MINING AND MINERAL ENGINEERING,756,679,77,Engineering,0.101851852,7,640,556,170,388,85,0.117241379,75000,55000,90000,350,257,50'],\n",
       " ['3,2415,METALLURGICAL ENGINEERING,856,725,131,Engineering,0.153037383,3,648,558,133,340,16,0.024096386,73000,50000,105000,456,176,0'],\n",
       " ['4,2417,NAVAL ARCHITECTURE AND MARINE ENGINEERING,1258,1123,135,Engineering,0.107313196,16,758,1069,150,692,40,0.050125313,70000,43000,80000,529,102,0'],\n",
       " ['5,2405,CHEMICAL ENGINEERING,32260,21239,11021,Engineering,0.341630502,289,25694,23170,5180,16697,1672,0.061097712,65000,50000,75000,18314,4440,972'],\n",
       " ['6,2418,NUCLEAR ENGINEERING,2573,2200,373,Engineering,0.144966965,17,1857,2038,264,1449,400,0.177226407,65000,50000,102000,1142,657,244'],\n",
       " ['7,6202,ACTUARIAL SCIENCE,3777,2110,1667,Business,0.441355573,51,2912,2924,296,2482,308,0.095652174,62000,53000,72000,1768,314,259'],\n",
       " ['8,5001,ASTRONOMY AND ASTROPHYSICS,1792,832,960,Physical Sciences,0.535714286,10,1526,1085,553,827,33,0.021167415,62000,31500,109000,972,500,220'],\n",
       " ['9,2414,MECHANICAL ENGINEERING,91227,80320,10907,Engineering,0.119558903,1029,76442,71298,13101,54639,4650,0.057342278,60000,48000,70000,52844,16384,3253']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read `recent-grads.csv` in to an RDD.\n",
    "f = sc.textFile('recent-grads.csv')\n",
    "data = f.map(lambda line: line.split('\\n'))\n",
    "data.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
