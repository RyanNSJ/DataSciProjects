{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NAs with Numeric Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns with more than half the rows having NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_count = len(df) / 2\n",
    "df = df.dropna(thresh=half_count, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Only Columns of A Certain Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=[\"int\",\"float\"], exclude=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Figures and Subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "gradients = [5,10,15,20,25,30]\n",
    "x = np.linspace(-2*np.pi,2*np.pi,200)\n",
    "\n",
    "for i,g in enumerate(gradients):\n",
    "    ax = fig.add_subplot(3,2,i+1) # (Rows, Columns, Graph Num)\n",
    "    ax.set_title(\"$sin({}x)$\".format(g))\n",
    "    ax.plot(np.sin(g*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshuffle Data Set [DataFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_rows = np.random.permutation(df.index)\n",
    "shuffled_df = df.iloc[shuffled_rows]\n",
    "\n",
    "# OR\n",
    "\n",
    "df = df.reindex(numpy.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and Shuffle [DataFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the Data Set\n",
    "train = df.sample(frac=0.8, random_state=1)\n",
    "test = df[~df.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and Shuffle [Arrays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # need scikit-learn 0.19.2 for shuffle\n",
    "\n",
    "X=[1,2,3,4,5,6,7,8,9,10]\n",
    "y = ['one', 'two', 'three','four','five','six','seven','eight','nine','ten']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=None, random_state=1, shuffle=True)\n",
    "\n",
    "print(X_train, X_test)\n",
    "print(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation [MSE] + KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "knn = KNeighborsRegressor()\n",
    "mses = cross_val_score(estimator=knn, X=dc_listings[[\"accommodates\"]], y=dc_listings[\"price\"], scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "rmses = np.sqrt(abs(mses))\n",
    "avg_rmse = np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "final_corr_cols = strong_corrs.drop(['Garage Cars', 'TotRms AbvGrd'])\n",
    "features = final_corr_cols.drop(['SalePrice']).index\n",
    "target = 'SalePrice'\n",
    "\n",
    "test = test[final_corr_cols.index]\n",
    "clean_test = test.dropna(axis=0)\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(train[features],train[target])\n",
    "train_predictions = lm.predict(train[features])\n",
    "train_rmse = np.sqrt(mean_squared_error(train[\"SalePrice\"],train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_cylinders = pd.get_dummies(cars[\"cylinders\"], prefix=\"cyl\")\n",
    "cars = pd.concat([cars, dummy_cylinders], axis=1)\n",
    "\n",
    "dummy_years = pd.get_dummies(cars[\"year\"], prefix=\"year\")\n",
    "cars = pd.concat([cars, dummy_years], axis=1)\n",
    "\n",
    "cars.drop([\"year\",\"cylinders\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col_name in [\"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
    "                 \"relationship\", \"race\", \"sex\", \"native_country\",\n",
    "                 \"high_income\"]:\n",
    "    categories = income[col_name].astype(\"category\")\n",
    "    income[col_name] = categories.cat.codes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Choice Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_clusters = 5\n",
    "# Use numpy's random function to generate a list, length: num_clusters, of indices\n",
    "random_initial_points = np.random.choice(point_guards.index, size=num_clusters)\n",
    "# Use the random indices to create the centroids\n",
    "centroids = point_guards.loc[random_initial_points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "-summation of (prob*log(prob)) for all unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_1 = income[income[\"high_income\"]==1].shape[0]/income.shape[0]\n",
    "prob_0 = income[income[\"high_income\"]==0].shape[0]/income.shape[0]\n",
    "\n",
    "\n",
    "income_entropy = -( (prob_1*math.log(prob_1,2)) + (prob_0*math.log(prob_0,2)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Gain\n",
    "entropy - summation( class_weight * entropy(class) ) for each new class generated in the split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# A. Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smallest or Largest KEY in Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abd = {0: 8.165359086946255, 1: 4.041494056879455, 2: 3.025911506812519, 3: 17.652380991140518, 4: 14.111415188949815}\n",
    "print(min(abd, key=abd.get))\n",
    "print(max(abd, key=abd.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Index of Max in List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "highest_gain_index = information_gains.index(max(information_gains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Pandas Maximum Columns Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 53)\n",
    "pd.get_option(\"display.max_columns\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
