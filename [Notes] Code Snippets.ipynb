{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NAs with Numeric Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns with more than half the rows having NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_count = len(df) / 2\n",
    "df = df.dropna(thresh=half_count, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Only Columns of A Certain Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=[\"int\",\"float\"], exclude=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Prefixes and Suffixes into Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert object columns to float columns\n",
    "df[\"percentages\"] = df[\"percentages\"].str.rstrip('%').astype(\"float\")\n",
    "df[\"dollars\"] = df[\"dollars\"].str.lstrip('$').astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Figures and Subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "gradients = [5,10,15,20,25,30]\n",
    "x = np.linspace(-2*np.pi,2*np.pi,200)\n",
    "\n",
    "for i,g in enumerate(gradients):\n",
    "    ax = fig.add_subplot(3,2,i+1) # (Rows, Columns, Graph Num)\n",
    "    ax.set_title(\"$sin({}x)$\".format(g))\n",
    "    ax.plot(np.sin(g*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshuffle Data Set [DataFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_rows = np.random.permutation(df.index)\n",
    "shuffled_df = df.iloc[shuffled_rows]\n",
    "\n",
    "# OR\n",
    "\n",
    "df = df.reindex(numpy.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and Shuffle [DataFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the Data Set\n",
    "train = df.sample(frac=0.8, random_state=1)\n",
    "test = df[~df.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and Shuffle [Arrays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # need scikit-learn 0.19.2 for shuffle\n",
    "\n",
    "X=[1,2,3,4,5,6,7,8,9,10]\n",
    "y = ['one', 'two', 'three','four','five','six','seven','eight','nine','ten']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=None, random_state=1, shuffle=True)\n",
    "\n",
    "print(X_train, X_test)\n",
    "print(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation [MSE] + KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "knn = KNeighborsRegressor()\n",
    "mses = cross_val_score(estimator=knn, X=dc_listings[[\"accommodates\"]], y=dc_listings[\"price\"], scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "rmses = np.sqrt(abs(mses))\n",
    "avg_rmse = np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validated Prediction + Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "predictions = cross_val_predict(lr, X_train, y_train, cv=3)\n",
    "\n",
    "tn = predictions[(predictions==0)&(y_train==0)].shape[0]\n",
    "tp = predictions[(predictions==1)&(y_train==1)].shape[0]\n",
    "fn = predictions[(predictions==0)&(y_train==1)].shape[0]\n",
    "fp = predictions[(predictions==1)&(y_train==0)].shape[0]\n",
    "\n",
    "fpr = fp/(tn+fp)\n",
    "tpr = tp/(tp+fn)\n",
    "\n",
    "print(fpr)\n",
    "print(tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "final_corr_cols = strong_corrs.drop(['Garage Cars', 'TotRms AbvGrd'])\n",
    "features = final_corr_cols.drop(['SalePrice']).index\n",
    "target = 'SalePrice'\n",
    "\n",
    "test = test[final_corr_cols.index]\n",
    "clean_test = test.dropna(axis=0)\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(train[features],train[target])\n",
    "train_predictions = lm.predict(train[features])\n",
    "train_rmse = np.sqrt(mean_squared_error(train[\"SalePrice\"],train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_cylinders = pd.get_dummies(cars[\"cylinders\"], prefix=\"cyl\")\n",
    "cars = pd.concat([cars, dummy_cylinders], axis=1)\n",
    "\n",
    "dummy_years = pd.get_dummies(cars[\"year\"], prefix=\"year\")\n",
    "cars = pd.concat([cars, dummy_years], axis=1)\n",
    "\n",
    "cars.drop([\"year\",\"cylinders\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col_name in [\"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
    "                 \"relationship\", \"race\", \"sex\", \"native_country\",\n",
    "                 \"high_income\"]:\n",
    "    categories = income[col_name].astype(\"category\")\n",
    "    income[col_name] = categories.cat.codes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Choice Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_clusters = 5\n",
    "# Use numpy's random function to generate a list, length: num_clusters, of indices\n",
    "random_initial_points = np.random.choice(point_guards.index, size=num_clusters)\n",
    "# Use the random indices to create the centroids\n",
    "centroids = point_guards.loc[random_initial_points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "-summation of (prob*log(prob)) for all unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_1 = income[income[\"high_income\"]==1].shape[0]/income.shape[0]\n",
    "prob_0 = income[income[\"high_income\"]==0].shape[0]/income.shape[0]\n",
    "\n",
    "\n",
    "income_entropy = -( (prob_1*math.log(prob_1,2)) + (prob_0*math.log(prob_0,2)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Gain\n",
    "entropy - summation( class_weight * entropy(class) ) for each new class generated in the split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# A. Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smallest or Largest KEY in Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abd = {0: 8.165359086946255, 1: 4.041494056879455, 2: 3.025911506812519, 3: 17.652380991140518, 4: 14.111415188949815}\n",
    "print(min(abd, key=abd.get))\n",
    "print(max(abd, key=abd.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Index of Max in List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "highest_gain_index = information_gains.index(max(information_gains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Pandas Maximum Columns Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 53)\n",
    "pd.get_option(\"display.max_columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Mapping and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123321', 'palindrordnilap']\n",
      "[6, 8, 5, 15]\n"
     ]
    }
   ],
   "source": [
    "strings = [\"12.1\", \"13.0\", \"14.4\"]\n",
    "floats = list(map(float,strings))\n",
    "\n",
    "\n",
    "def is_palindrome(my_string):\n",
    "    return my_string == my_string[::-1]\n",
    "\n",
    "passwords = [\"123321\", \"password\", \"wrong\", \"palindrordnilap\"]\n",
    "\n",
    "palindrome_passwords = list(filter(is_palindrome,passwords))\n",
    "print(palindrome_passwords)\n",
    "\n",
    "pw_lengths = list(map(len,passwords))\n",
    "print(pw_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lambda arg1, arg2, etc. : perform task on arg1 and arg2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "passwords = [\"123321\", \"password\", \"wrong\", \"palindrordnilap\"]\n",
    "palindrome_passwords = list(filter(lambda x : x == x[::-1], passwords))\n",
    "\n",
    "# OR\n",
    "\n",
    "def is_palindrome(x):\n",
    "    return x == x[::-1]\n",
    "palindrome_passwords = list(filter(is_palindrome,passwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_dict(dictionary):\n",
    "    pd.Series(dictionary).plot.bar(figsize=(9,6),\n",
    "                                   ylim=(0.78,0.83),rot=0)\n",
    "    plt.show()\n",
    "\n",
    "knn_scores = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing A List of Dictionaries Values to a Single Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 20, 'b': 50, 'c': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "a = {\"a\":20,\n",
    "    \"b\":10,}\n",
    "\n",
    "b = {\"b\":40,\n",
    "    \"c\":10,}\n",
    "\n",
    "dict_list = [a,b]\n",
    "\n",
    "sum_dict = sum(map(Counter, dict_list),Counter())\n",
    "\n",
    "# Counter count Object -> dict object\n",
    "dict(sum_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
